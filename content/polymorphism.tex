One of the most glaring omissions from \mlsyn{} and \myth{} is polymorphism.
Without polymorphism, our $\mlist$ and $\mtree$ data types from \autoref{ch:recursion} must have concrete carrier types, usually $\mnat$s.
Beyond not being able to synthesize programs that more closely resemble real-world typed, functional programs, the lack of polymorphism also impacts efficiency.
To see this, consider performing raw term enumeration at the $\mlist$ data type (carrier type $\mnat$) with the $\mkwd{append}$ function of type $\mlist → \mlist → \mlist$.
Suppose that we also have variables $l_1$ and $l_2$ of type $\mlist$ in the context.
Then we will enumerate $E$-terms such as:
\begin{gather*}
  \mkwd{append}\,l_1\,l_2 \\
  \mkwd{append}\,l_1\,(\mkwd{append}\,l_1\,l_2) \\
  \mkwd{append}\,(\mkwd{append}\,l_1\,l_2)\,l_2
\end{gather*}
As we observed in \autoref{ch:evaluating-myth}, functions like $\mkwd{append}$ pose a problem for $E$-term generation as they greatly increase the number of programs that we synthesize, many of which are equivalent.
However, on top of these $E$-terms, we will also enumerate these $E$-terms:
\begin{gather*}
  \mkwd{append}\,l_1\,[0] \\
  \mkwd{append}\,l_2\,[1] \\
  \mkwd{append}\,[0]\,[0] \\
  \mkwd{append}\,[1]\,[0] \\
  \mkwd{append}\,[0]\,[1] \\
  \mkwd{append}\,[1]\,[1].
\end{gather*}
These $E$-terms are problematic because they expose the fact that the carrier type of $\mlist$ is concrete even though it is likely that the satisfying program does not require a particular carrier type.
While we are forced to explore all of these possible programs, they are all very unlikely to be satisfying programs for this reason.

If we had polymorphic types, then we could assign $\mkwd{append}$ the polymorphic type $∀α.\,α\,\mlist → α\,\mlist → α\,\mlist$.
With this type, we would simply be unable to synthesize $E$-terms like the latter set above; they would be ill-typed because the carrier type of the $\mlist$ is held abstract!
This has the potential to be an enormous performance win as we are able to prune a large number of candidate terms from the search space when synthesizing programs over $\mlist$s, $\mtree$s, and other generic data types.

\section{From System F to Polymorphic Program Synthesis}
\label{sec:from-system-f-to-polymorphic-program-synthesis}

\input{figures/system-f-syn-defn}

To add polymorphism to our synthesis calculi, we apply the same trick of turning the type checking rules for polymorphic values into synthesis rules.
We start our exploration with System F~\citep{girard-thesis-1972}, the simply-typed lambda calculus extended with universal quantification.
\autoref{fig:system-f-syn-defn} gives the definition of \systemfsyn{}, our extension of System F for type-directed program synthesis.
The polymorphic type $∀α.\,τ$ possesses an introduction form, the type abstraction $Λα.\,e$, and an elimination form, the type application $e\,[τ]$.
For example, we would write down the polymorphic identity function of type $∀α.\,α → α$ as
\[
  Λα.\,λx{:}α.\,x.
\]

The static and dynamic semantics of these new constructs is straightforward.
Type checking a type abstraction (\rulename{t-Itabs}) requires that we check the abstracted type under an extended context that records the type variable $α$.
A type application is well-typed (\rulename{t-Etapp}) whenever a type abstraction of type $∀α.\,τ_1$ is applied to a well-formed type (checked with the well-formed type judgment $Γ ⊢ τ$).
The result of the type application is an instantiated version of the polymorphic type $τ_1$ where all occurrences of $α$ have been replaced by the argument type $τ$.
Finally, the reduction rule for type application is also simple ($\rulename{eval-tapp}$) where we substitute the type argument throughout the body of the type abstraction.

\section{Synthesizing Type Applications}
\label{sec:synthesizing-type-applications}

With the typing rules for \systemfsyn{} set, we can now begin the process of creating synthesis rules for polymorphic values from \systemfsyn{}'s typing judgment.
Let us start with synthesizing type applications.
Na\"{i}vely transforming the rule for type checking type applications, \rulename{t-Etapp}, into an $E$-guessing rule produces the following:
\[
\fbox{$Γ ⊢ τ ⇝ E$} \qquad
\inferrule[eguess-tapp]
  {Γ ⊢ ∀α.\,τ_1 ⇝ E \\ Γ ⇝ τ}
  {Γ ⊢ [τ/α] τ_1 ⇝ E\,[τ]}
\]
A straightforward reading of this synthesis rule says that we can synthesize a type application whenever our goal type \emph{anti-unifies} with some universal type that we can $E$-guess and a well-formed type that we can generate.
Like the $E$-guessing rule for $μ$-types (\autoref{sec:mu-types}), \rulename{eguess-tapp} requires that we guess the universal type and the instantiation that will allow us to synthesize a term of the goal type through a single type application.

With recursive types, we circumvented this problem by rolling recursive types into algebraic data types and functions.
And with other simple type extensions, we appealed to focusing (\autoref{subsec:tuple-efficiency}) to avoid guessing.
However, in those cases, there were a finite number of eliminations we could perform, \ie, a finite number of tuple or record components.
With polymorphism, there are an infinite number of type applications we could perform because a polymoprhic value can be instantiated to any type!

We can mitigate this problem by performing a breadth-first search of the polymorphic instantiations in order of increasing size of type.
That is, when $E$-guessing, we can initially focus on the possible complete instantiations of all polymorphic variables in the context of base type (size one).
For example, with $\mnat$ and $\mbool$ in the context, we would explore the following instantiations of the polymorphic $\mkwd{map}$ function:
\begin{gather*}
  \mkwd{map}\,[\mnat]\,[\mnat] \\
  \mkwd{map}\,[\mnat]\,[\mbool] \\
  \mkwd{map}\,[\mbool]\,[\mnat] \\
  \mkwd{map}\,[\mbool]\,[\mbool]
\end{gather*}
In successive $E$-guessing phases, we would expand our search to types of increasing size, \eg, arrows at base types, arrows of arrows, and so forth.
In the presence of many base types and polymorphic types with multiple arguments, the number of instantiations grows quickly as we must consider all the possible ways of combining these base types to fully instantiate each polymorphic type.
This blows up the size of our context, but  in practice, we will only need to explore instantiations at depth one or two (corresponding to base types and instantiated polymorphic types] as it is rare to instantiate a polymoprhic function at arrow type.

\section{Examples for Polymorphic Values}
\label{sec:examples-for-polymorphic-values}

Now, let's turn our attention towards synthesizing the polymorphic introduction form, the type abstraction.
This requires that we define our example value $χ$ for a polymorphic type.
Because type abstractions are values, it is tempting to designate the type abstraction as the example value of polymorphic type, \ie,
\[
χ \bnfdef … \bnfalt Λα.\,χ.
\]
However, this turns out to be a bad choice of example value!
To see this, imagine defining an example corresponding to the polymorphic identity function:
\[
  Λα.\, ? ⇒ ?
\]
If we were in a monomorphic setting, for example, we were defining the identity function over $\mnat$s, we could write a concrete input/output pair $0 ⇒ 0$.
But here we must fill in the question marks with values of the abstract type $α$, and we have no such values available!

\subsection{Polymorphic Constants}
\label{subsec:polymorphic-constants}

Thus, the type abstraction value is not suitable as an example value on its own as it does not provide any values of abstract type for us to use.
However, we can simply enhance our type abstraction example value construct to provide this information!
\[
  \begin{array}{l}
    v \bnfdef … \bnfalt q \\
    χ \bnfdef … \bnfalt Λq_1, …, q_k:α.\,χ \bnfalt q \\
  \end{array}
\]
Rather than just introducing an abstract type $α$, the type abstraction example value also introduces \emph{polymorphic constants} $q_1, …, q_k$ that can be used in $χ$.
For example, we can now specify the polymorphic identity function easily,
\[
  Λq:α.\,q ⇒ q.
\]
We allow the type abstraction example value to specify multiple constants so that we can capture relationship between polymorphic values in examples.
For example, suppose that we lifted our polymorphic system to \mlsyn{}.
Then the polymorphic $\mkwd{stutter}$ function might take the following examples as specification:
\begin{align*}
  Λq_1, q_2:α.\,& [] ⇒ [] \\
  \bnfalt & [q_1] ⇒ [q_1] \\
  \bnfalt & [q_2, q_1] ⇒ [q_2, q_2, q_1, q_1]
\end{align*}
Importantly, our polymorphic constants have decidability, identity-based equality that we employ in our compatibility check,
\[
  \inferrule[eq-pconst]
    {}
    {q ≃ q}
\]
which allows us to distinguish between $q_1$ and $q_2$ in the above example during synthesis.

Note that our polymorphic values are not constructs that the user can synthesize\footnote{%
  Indeed, no rule of \systemfsyn{} can synthesize a polymoprhic constant $q$.
}.
You can think of them as abstract values or placeholders for polymorphic values that will be bound to variables in our example worlds' environments.
For example, in the above example of the polymorphic identity function, if we synthesize the partial program:
\[
  Λα.\,λx{:}α.\,◼.
\]
Then at the program hole, $x$ would be bound to the polymorphic constant $q$ in our sole example world.
This means that while we can write down example values of type $∀α.\,α$, for example, $Λq:α.\,q$, we will be unable to synthesize any terms of this type .
(Which is good, because $∀α.\,α$ is uninhabited!)

\input{figures/system-f-syn-synthesis-a}

\autoref{fig:system-f-syn-synthesis-a} gives the enhanced syntax and synthesis rules for \systemfsyn{}.
$I$-refinement of universal quantification is handled by \rulename{irefine-forall} where we synthesize a type abstraction.
Because the examples are well-typed, they must be type abstraction example values.
We assume that before synthesis (\eg, during type checking), that we \emph{normalize} the type abstraction example values so that they all declare exactly the same set of polymorphic constants.
Then, example refinement simply amounts to stripping off the binders of the example values, recording them in the context, and synthesizing with the remaining nested example values.
While we record the type variable associated with the polymorphic constants, this is unnecessary because we never need to refer to their types again; we merely compare the constants for equality via $\rulename{ex-pconst}$ during the synthesis process.

Finally, closing the loop on synthesis with polymorphic values, we must extend our compatibility check to type abstractions.
Because we only check compatibility at well-typed program values and example values, we know that we must be comparing a type abstraction value to a type abstraction example value at universal type.
(Recall that in \lsyn{}, we separated the syntax of program values and example values, only joining them together in \mlsyn{} to support partial-functions-as-program values).
To do this, we simply want to check their bodies for compatibility.
However, we encounter a slight complication: the body of a type abstraction program value is an arbitrary $I$ rather than a $v$---in particular, the body could be an $E$ with pending reductions.
To get around this, we evaluate the body of the value type abstraction and compare the resulting value to the example value body (\rulename{eq-tabs}).

As a complete example, we revisit the encoding of the boolean $\mkwd{if}$ function from \autoref{subsec:example-specification-in-stlc}.
With polymorphic types, we can assign the boolean type and values the following lambda terms:
\begin{align*}
  \mbool  &≝ ∀α.\,α → α → α   \\
  \mtrue  &≝ Λα.\,λt{:}α.\,λf{:}α.\,t \\
  \mfalse &≝ Λα.\,λt{:}α.\,λf{:}α.\,f
\end{align*}
In this setting, $\mkwd{if}$ has the type $∀α.\,\mbool → α → α → α$.
(Note that this type has a nested quantifier in the type synonym $\mbool$.)
Our specification of the desired function is the example value:
\[
  χ = Λq_1, q_2{:}α.\,\mtrue ⇒ q_1 ⇒ q_2 ⇒ q_1 \bnfalt \mfalse ⇒ q_1 ⇒ q_2 ⇒ q_2.
\]

Starting with the initial goal of
\[
  ◼ : ∀α.\,\mbool → α → α → α,
\]
we apply \rulename{irefine-forall} to create the top-level type abstraction
\[
  Λα.\,◼ : \mbool → α → α → α,
\]
where we have introduced two polymorphic constants $q_1$ and $q_2$ into the context.
From here, synthesis proceeds almost identically to our \lsyn{} development.
We apply \rulename{irefine-arr} multiple times to arrive a base goal type
\[
  Λα.\,λb{:}\mbool.\,λt{:}α.\,λf{:}α.\,◼ : α.
\]
Our examples have been refined to two worlds:
\[
  \begin{array}{l}
    [\mtrue / b][q_1 / t][q_2 / f] ↦ q_1 \\[0pt]
    [\mfalse / b][q_1 / t][q_2 / f] ↦ q_2.
  \end{array}
\]
To guess the body of the function, we invoke \rulename{irefine-eguess} to guess an elimination form.
We would like to synthesize the satisfying expression $b\,t\,f$ as in \autoref{ch:a-simple-synthesis-calculus}.
However, because $\mbool$ is now polymorphic, we must first instantiate it to the correct type, $α$, using \rulename{eguess-tapp}.
The complete derivation tree corresponding to this $E$-guessed expression is:
\[
  \inferrule*[Left=eguess-app]
    {\inferrule*[Left=eguess-app]
      {\inferrule*[Left=eguess-tapp]
        {\inferrule*[Left=eguess-var]
          {b{:}∀α.\,α → α → α ∈ Γ}
          {Γ ⊢ ∀α.\,α → α → α ⇝ b} \\
          {\inferrule*[lab=tguess-tvar]
            {α{:}* ∈ Γ}
            {Γ ⇝ α}
          }
        }
        {Γ ⊢ α → α → α ⇝ b\,[α]} \\
        \inferrule*[lab=eguess-var]
          {t{:}α ∈ Γ}
          {Γ ⊢ α ⇝ t}
      }
      {Γ ⊢ α → α ⇝ b\,[α]\,t} \\
      \inferrule*[lab=eguess-var]
        {f{:}α ∈ Γ}
        {Γ ⊢ α ⇝ f}
    }
    {Γ ⊢ α ⇝ b\,[α]\,t\,f}
\]

\subsection{Polymorphic Instances}
\label{subsec:polymorphic-instances}

The type abstraction example value that we developed in the previous section works for specifying values of polymorphic type.
However, they are not the most natural way of specifying such examples.
For example, rather than declaring and using abstract polymorphic constants to specify the behavior of $\mkwd{stutter}$,
\begin{align*}
  Λq_1, q_2:α.\,& [] ⇒ [] \\
  \bnfalt & [q_1] ⇒ [q_1] \\
  \bnfalt & [q_2, q_1] ⇒ [q_2, q_2, q_1, q_1],
\end{align*}
it would be more convenient to specify concrete \emph{instantiations} of $\mkwd{stutter}$ such as
\begin{align*}
  [\mnat] & ([] ⇒ [] \\
  & [0] ⇒ [0] \\
  & [1,0] ⇒ [1,1,0,0]),
\end{align*}
which is identical to the monomorphic case but an explicit type annotations for the universal type.\footnote{%
  In a real implementation, we could instead infer these type annotations making the input/output examples identical to our original presentation of $\mkwd{stutter}$.
}

This suggests an alternative example value for polymorphic types---the \emph{polymorphic instance}:
\[
  χ \bnfdef … \bnfalt [τ]\,χ.
\]
Rather than requiring the user to specify polymorphic binders, we allow them to use concrete values along with a concrete type instantiation instead.
When using these concrete values, we need to remember in each example world what these type instantiations are so that we can 
We might do this by recording \emph{type equalities} for each example world.
For example, when refining the single example world $[\mnat] 0 ⇒ 0$ for a goal type $∀α.\,α → α$, we will eventually end up with the refined world
\[
  [α ~ \mnat][0 / x] ↦ 0
\]
where we remember the top-level polymorphic type variable $α$ is instantiated to $\mnat$ in this world, written $α ~ \mnat$.
However, the problem is that we can easily abuse this type equality to create invalid code.
Say that we have this example world with the partial program skeleton $Λα.λx{:}α.\,(◼ : α)$.
It would be unsound to use this type equality to synthesize $0$ for the whole, even if this value agrees with the example, because the hole is held to an abstract type $α$.

Rather than recording type equalities that could apply to an entire example world, we must instead record that the example values really have polymorphic type even though they are concrete values (of a particular, known type).
To do this, we introduce \emph{boxed polymorphic expression}, written $\pbox{e}{α}$, that records that a particular expression ought to be treated as if had type $α$.
These boxes behave similarly to the polymorphic constants in that they are opaque to the outside world, but allow for testable equality (as long as the carrier type of the box also has testable equality).
When refining a polymorphic instance value of the form $[τ_1]\,χ$ at goal type $∀α.\,τ$, we box any sub-expression of $χ$ that would have type $α$ when type checking $χ$ against the polymorphic type $∀.\,τ$.
For example, if our example value was:
\[
  [\mnat] λx{:}\mnat.\,x ⇒ 0 ⇒ 1 ⇒ 0
\]
and our goal type at this point in the synthesis process was $∀α.\,(α → α) ⇒ \mnat ⇒ α ⇒ α$.
Then our boxing operation would result in the following modified example value
\[
  λx{:}α.\,\pbox{x}{α} ⇒ 0 ⇒\pbox{1}{α} ⇒ \pbox{0}{α}.
\]
Note that in addition to adding boxes in every position where we expected a value of type $α$ according to the goal type, we also modified the lambda's type annotation to reflect the fact that it is also takes an $α$ as an argument according to the goal type.
Because we are interested in determining every sub-term that has type $α$ according to the goal type, the box transformation function $\mfbox$ is the standard type checking algorithm but modified to box every such sub-term along the way.

Rather than formalize this approach completely, we observe that the instances based-approach to providing polymorphic examples is functionally equivalent to the constants-based approach we discussed in \autoref{subsec:polymorphic-constants}!
The effect of the $\mfbox$ transformation function is to take a concrete example value and abstract it according to the polymorphic goal type.
And the polymorphic constants are equivalent to the boxed terms that $\mfbox$ creates---they are both opaque values that we can test for equality.
With this in mind, we can view polymorphic constants as the form of our example values that is simpler to reason about while polymorphic instantiations offer the user a more flexible way of specifying examples but at the cost of additional complexity.

\section{The Metatheory of Polymorphism}
\label{sec:polymorphism-metatheory}

We close our discussion of polymorphism by stating and proving the necessary lemmas for soundness and completeness of \systemfsyn{}.

\begin{lemma}[Example-Type Preservation of Polymorphism]
\label{lem:example-type-preservation-of-polymorphism}
If $Γ ⊢ Χ : ∀α.\,τ$ then $q_1{:}α, …, q_k{:}α, α{:}*, Γ ⊢ Χ' : τ$ where $Χ = \many{σ_i ↦ Λq_1, …, q_k{:}α.\, χ_i}{i < m}$ and $Χ' = \many{σ_i ↦ χ_i}{i < m}$.
\end{lemma}
\begin{proof}
  Consider $σ ↦ Λq_1, …, q_k{:}α.\,χ_i ∈ Χ$.
  Because $Χ$ is well-typed, we know that $σ$ and the type abstraction are well-typed.
  By inversion on \rulename{ex-tabs}, we know that $χ$ is well-typed under the context $q_1{:}α, …, q_k{:}α, α{:}*, Γ$ which is sufficient to conclude that $Χ'$ is well-typed.
\end{proof}

\begin{lemma}[Logicality of Polymorphism]
  \label{lem:logicality-of-polymorphism}
  If $I ⊨ Χ'$, then $Λα.\,I ⊨ Χ$ where $Χ = \many{σ_i ↦ Λq_1, …, q_k{:}α.\, χ_i}{i < m}$ and $Χ' = \many{σ_i ↦ χ_i}{i < m}$.
\end{lemma}
\begin{proof}
  Consider a single $σ ↦ χ ∈ Χ'$.
  By the definition of satisfaction for $I$, $σ(I) ⟶^* v$ and $v ≃ χ$.
  Now, by unrolling the definition of satisfaction for $Λα.\,I$, we learn that we must show that
  \[
    σ(Λα.\,I) = Λα.\,σ(I) ≃ Λq_1, …, q_k{:}α.\,χ_i.
  \]
  However, this is immediate from \rulename{eq-tabs} and the fact that $v ≃ χ$.
\end{proof}

\begin{lemma}[Satisfaction Preservation of Polymorphism]
\label{lem:satisfaction-preservation-of-polymorphism}
  If $Λα.\,I ⊨ Χ$ then $I ⊨ Χ'$ where $Χ = \many{σ_i ↦ Λq_1, …, q_k{:}α.\, χ_i}{i < m}$ and $Χ' = \many{σ_i ↦ χ_i}{i < m}$.
\end{lemma}
\begin{proof}
  Consider a single $σ ↦ Λq_1, …, q_k{:}α.\,χ_i ∈ Χ$.
  By the definition of satisfaction for $Λα.\,I$,
  \[
    σ(Λα.\,I) = Λα.\,σ(I) ≃ Λq_1, …, q_k{:}α.\,χ_i.
  \]
  Now, by unrolling the definition of satisfaction for $I$, we learn that we must show that $v ≃ χ$ where $σ(I) ⟶^* v$.
  However, we know this by inversion of \rulename{ex-tabs} on the compatibility of the type abstraction values above.
\end{proof}
